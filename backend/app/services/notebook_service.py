"""
Notebook Service for managing notebook persistence and operations.

This service handles saving, loading, and managing notebook files,
as well as coordinating between LLM and execution services.
"""

import json
import os
import uuid
from uuid import UUID
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime
import logging

from ..models.notebook import (
    Notebook, Cell, CellType, ExecutionResult, ExecutionStatus, CellState,
    NotebookCreateRequest, NotebookUpdateRequest,
    CellCreateRequest, CellUpdateRequest, CellExecuteRequest
)
from .llm_service import LLMService
from .execution_service import ExecutionService
from .pdf_service_scientific import ScientificPDFService
from .semantic_service import SemanticExtractionService
from .semantic_analysis_service import SemanticAnalysisService
from .semantic_profile_service import SemanticProfileService

logger = logging.getLogger(__name__)


class NotebookService:
    """Service for managing notebooks and coordinating cell operations."""
    
    def __init__(self, notebooks_dir: str = "notebooks"):
        """
        Initialize the notebook service.
        
        Args:
            notebooks_dir: Directory to store notebook files
        """
        logger.info("ðŸš€ INITIALIZING NOTEBOOK SERVICE")
        
        try:
            # Ensure notebooks directory is relative to project root, not current working directory
            if not os.path.isabs(notebooks_dir):
                # Get the project root (4 levels up from this file)
                project_root = Path(__file__).parent.parent.parent.parent
                self.notebooks_dir = project_root / notebooks_dir
            else:
                self.notebooks_dir = Path(notebooks_dir)
                
            self.notebooks_dir.mkdir(exist_ok=True)
            logger.info(f"âœ… Notebook service using directory: {self.notebooks_dir}")
            
            # Initialize services
            logger.info("ðŸ”„ Initializing LLM service...")
            self.llm_service = LLMService()
            logger.info("âœ… LLM service initialized")
            
            logger.info("ðŸ”„ Initializing execution service...")
            self.execution_service = ExecutionService()
            logger.info("âœ… Execution service initialized")
            
            logger.info("ðŸ”„ Initializing scientific PDF service...")
            self.pdf_service = ScientificPDFService()
            logger.info("âœ… Scientific PDF service initialized")

            logger.info("ðŸ”„ Initializing semantic extraction service...")
            self.semantic_service = SemanticExtractionService()
            logger.info("âœ… Semantic extraction service initialized")

            logger.info("ðŸ”„ Initializing analysis graph service...")
            self.analysis_graph_service = SemanticAnalysisService()
            logger.info("âœ… Analysis graph service initialized")

            logger.info("ðŸ”„ Initializing profile graph service...")
            self.profile_graph_service = SemanticProfileService()
            logger.info("âœ… Profile graph service initialized")

            # Get data manager for file context
            logger.info("ðŸ”„ Getting data manager...")
            from .data_manager_clean import get_data_manager
            self.data_manager = get_data_manager()
            logger.info("âœ… Data manager initialized")
            
            # In-memory notebook cache
            self._notebooks: Dict[str, Notebook] = {}
            
            # Load existing notebooks
            logger.info("ðŸ”„ Loading existing notebooks...")
            self._load_notebooks()
            logger.info(f"âœ… Loaded {len(self._notebooks)} notebooks")
            
            logger.info("ðŸŽ‰ NOTEBOOK SERVICE INITIALIZATION COMPLETE")
            
        except Exception as e:
            logger.error(f"ðŸ’¥ FAILED TO INITIALIZE NOTEBOOK SERVICE: {e}")
            logger.error(f"ðŸ’¥ Exception type: {type(e)}")
            import traceback
            logger.error(f"ðŸ’¥ Full traceback:\n{traceback.format_exc()}")
            raise
    
    def _load_notebooks(self):
        """Load all notebooks from disk."""
        try:
            for notebook_file in self.notebooks_dir.glob("*.json"):
                # Skip temporary files
                if notebook_file.name.endswith('.tmp'):
                    continue
                    
                try:
                    with open(notebook_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    notebook = Notebook(**data)
                    self._notebooks[str(notebook.id)] = notebook
                    logger.info(f"Loaded notebook: {notebook.title}")
                    
                except json.JSONDecodeError as e:
                    logger.error(f"Corrupted JSON in notebook {notebook_file.name}: {e}")
                    logger.error(f"Consider moving {notebook_file.name} to a backup location for manual recovery")
                    # Optionally, move corrupted file to a backup location
                    backup_file = notebook_file.with_suffix('.json.corrupted')
                    try:
                        notebook_file.rename(backup_file)
                        logger.info(f"Moved corrupted file to {backup_file.name}")
                    except Exception as rename_error:
                        logger.error(f"Could not backup corrupted file: {rename_error}")
                        
                except Exception as e:
                    logger.error(f"Failed to load notebook {notebook_file.name}: {e}")
                    
        except Exception as e:
            logger.error(f"Failed to load notebooks: {e}")
    
    def create_notebook(self, request: NotebookCreateRequest) -> Notebook:
        """
        Create a new notebook.
        
        Args:
            request: Notebook creation parameters
            
        Returns:
            Created notebook
        """
        notebook = Notebook(
            title=request.title,
            description=request.description,
            author=request.author,
            llm_model=request.llm_model,
            llm_provider=request.llm_provider
        )
        
        # Add a default empty prompt cell for immediate use
        default_cell = notebook.add_cell(
            cell_type=CellType.PROMPT,
            content=""
        )
        
        # Cache and save
        notebook_id = str(notebook.id)
        self._notebooks[notebook_id] = notebook
        self._save_notebook(notebook)
        
        logger.info(f"Created new notebook: {notebook.title} with ID: {notebook_id}")
        logger.info(f"Notebooks in cache: {list(self._notebooks.keys())}")
        return notebook
    
    def _build_execution_context(self, notebook: Notebook, current_cell: Cell) -> Dict[str, Any]:
        """
        Build comprehensive execution context for LLM code generation.

        Includes:
        - Available variables in execution context
        - Previous cells (prompts and code) for context awareness
        - Data files available
        - Notebook metadata
        - Notebook ID and Cell ID for token tracking

        Args:
            notebook: Current notebook
            current_cell: Cell being executed

        Returns:
            Context dictionary for LLM with previous cell history
        """
        context = {}

        try:
            # Add basic notebook info
            context['notebook_title'] = notebook.title
            context['cell_type'] = current_cell.cell_type.value

            # Add IDs for token tracking (AbstractCore integration)
            context['notebook_id'] = str(notebook.id)
            context['cell_id'] = str(current_cell.id)

            # Add information about available data files
            try:
                execution_context = self.data_manager.get_execution_context()
                context.update(execution_context)
            except Exception as e:
                logger.warning(f"Could not get data manager context: {e}")

            # Get available variables from execution service
            try:
                variables = self.execution_service.get_variable_info()
                if variables:
                    context['available_variables'] = variables
                    logger.info(f"Added {len(variables)} available variables to context")
            except Exception as e:
                logger.warning(f"Could not get variable info: {e}")

            # Get previous cells context for LLM awareness
            previous_cells = []
            for cell in notebook.cells:
                if cell.id == current_cell.id:
                    break  # Stop at current cell
                if cell.cell_type in (CellType.PROMPT, CellType.CODE) and cell.code:
                    previous_cells.append({
                        'type': cell.cell_type.value,
                        'prompt': cell.prompt if cell.cell_type == CellType.PROMPT else None,
                        'code': cell.code[:500],  # Truncate long code to first 500 chars
                        'success': cell.last_result.status == ExecutionStatus.SUCCESS if cell.last_result else None,
                        'has_dataframes': bool(cell.last_result and cell.last_result.tables) if cell.last_result else False
                    })

            if previous_cells:
                context['previous_cells'] = previous_cells
                logger.info(f"Added {len(previous_cells)} previous cells to context")

            logger.info(f"Built execution context with {len(context)} context items")
            return context

        except Exception as e:
            logger.error(f"Error building execution context: {e}")
            return {}
    
    def _generate_fallback_code(self, prompt: str) -> str:
        """Generate simple fallback code when LLM is unavailable."""
        if "gene_expression" in prompt.lower():
            return """
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the gene expression data
df = pd.read_csv('data/gene_expression.csv')
print("Dataset shape:", df.shape)
print("\\nColumns:", df.columns.tolist())
print("\\nFirst 5 rows:")
print(df.head())

# Basic analysis
print("\\nBasic statistics:")
print(df.describe())
"""
        elif "patient" in prompt.lower():
            return """
import pandas as pd
import matplotlib.pyplot as plt

# Load patient data
df = pd.read_csv('data/patient_data.csv')
print("Dataset shape:", df.shape)
print("\\nFirst 5 rows:")
print(df.head())
"""
        else:
            return """
# Simple analysis
print("Hello! This is a basic analysis.")
print("LLM service is currently unavailable, using fallback code.")
"""
    
    def get_notebook(self, notebook_id: str) -> Optional[Notebook]:
        """
        Get a notebook by ID.
        
        Args:
            notebook_id: Notebook UUID
            
        Returns:
            Notebook or None if not found
        """
        return self._notebooks.get(notebook_id)
    
    def get_cell(self, cell_id: str) -> Optional[Cell]:
        """
        Get a cell by ID across all notebooks.
        
        Args:
            cell_id: Cell UUID
            
        Returns:
            Cell or None if not found
        """
        for notebook in self._notebooks.values():
            cell = notebook.get_cell(cell_id)
            if cell:
                return cell
        return None
    
    def list_notebooks(self) -> List[Notebook]:
        """
        Get all notebooks.
        
        Returns:
            List of all notebooks
        """
        return list(self._notebooks.values())
    
    def get_notebook_summaries(self) -> List[Dict[str, Any]]:
        """
        Get notebook summaries for browsing interface.
        
        Returns:
            List of notebook summaries with metadata and statistics
        """
        summaries = []
        
        for notebook in self._notebooks.values():
            # Calculate statistics based on content, not cell type
            total_cells = len(notebook.cells)
            executed_cells = sum(1 for cell in notebook.cells if cell.last_result and cell.last_result.status == ExecutionStatus.SUCCESS)
            
            # Count cells by actual content presence (more accurate than cell_type)
            cells_with_prompts = sum(1 for cell in notebook.cells if cell.prompt and cell.prompt.strip())
            cells_with_code = sum(1 for cell in notebook.cells if cell.code and cell.code.strip())
            cells_with_methodology = sum(1 for cell in notebook.cells if cell.scientific_explanation and cell.scientific_explanation.strip())
            cells_with_markdown = sum(1 for cell in notebook.cells if cell.markdown and cell.markdown.strip())
            
            # Get latest activity
            latest_activity = notebook.updated_at
            for cell in notebook.cells:
                if cell.updated_at > latest_activity:
                    latest_activity = cell.updated_at
            
            # Check if has content
            has_content = any(cell.prompt or cell.code or cell.markdown for cell in notebook.cells)
            has_results = any(cell.last_result and cell.last_result.status == ExecutionStatus.SUCCESS for cell in notebook.cells)
            
            # Create summary
            summary = {
                "id": str(notebook.id),
                "title": notebook.title,
                "description": notebook.description,
                "author": notebook.author,
                "created_at": notebook.created_at.isoformat(),
                "updated_at": notebook.updated_at.isoformat(),
                "latest_activity": latest_activity.isoformat(),
                "tags": notebook.tags,
                "llm_provider": notebook.llm_provider,
                "llm_model": notebook.llm_model,
                "statistics": {
                    "total_cells": total_cells,
                    "executed_cells": executed_cells,
                    "cells_with_prompts": cells_with_prompts,
                    "cells_with_code": cells_with_code,
                    "cells_with_methodology": cells_with_methodology,
                    "cells_with_markdown": cells_with_markdown,
                    "execution_rate": round(executed_cells / total_cells * 100, 1) if total_cells > 0 else 0
                },
                "status": {
                    "has_content": has_content,
                    "has_results": has_results,
                    "is_empty": total_cells == 0 or not has_content
                }
            }
            
            summaries.append(summary)
        
        # Sort by latest activity (most recent first)
        summaries.sort(key=lambda x: x["latest_activity"], reverse=True)
        
        return summaries
    
    def mark_cells_as_stale(self, notebook_id: str, from_cell_index: int) -> bool:
        """
        Mark all cells below the given index as stale.
        
        Args:
            notebook_id: Notebook UUID
            from_cell_index: Index of the cell that was re-run (0-based)
            
        Returns:
            True if cells were marked as stale, False if notebook not found
        """
        notebook = self._notebooks.get(notebook_id)
        if not notebook:
            return False
        
        # Mark all cells after the given index as stale
        cells_marked = 0
        for i in range(from_cell_index + 1, len(notebook.cells)):
            cell = notebook.cells[i]
            if cell.cell_state != CellState.STALE:
                cell.cell_state = CellState.STALE
                cell.updated_at = datetime.now()
                cells_marked += 1
        
        if cells_marked > 0:
            notebook.updated_at = datetime.now()
            self._save_notebook(notebook)
            logger.info(f"Marked {cells_marked} cells as stale in notebook {notebook.title}")
        
        return True
    
    def mark_cell_as_fresh(self, notebook_id: str, cell_id: UUID) -> bool:
        """
        Mark a specific cell as fresh (recently executed).
        
        Args:
            notebook_id: Notebook UUID
            cell_id: Cell UUID
            
        Returns:
            True if cell was marked as fresh, False if not found
        """
        notebook = self._notebooks.get(notebook_id)
        if not notebook:
            return False
        
        cell = notebook.get_cell(cell_id)
        if not cell:
            return False
        
        cell.cell_state = CellState.FRESH
        cell.updated_at = datetime.now()
        notebook.updated_at = datetime.now()
        self._save_notebook(notebook)
        
        logger.info(f"Marked cell {cell_id} as fresh in notebook {notebook.title}")
        return True
    
    def bulk_update_cell_states(self, notebook_id: str, cell_updates: List[Dict[str, Any]]) -> bool:
        """
        Update multiple cell states in bulk.
        
        Args:
            notebook_id: Notebook UUID
            cell_updates: List of dicts with 'cell_id' and 'state' keys
            
        Returns:
            True if updates were successful, False if notebook not found
        """
        notebook = self._notebooks.get(notebook_id)
        if not notebook:
            return False
        
        updated_count = 0
        for update in cell_updates:
            cell_id = update.get('cell_id')
            new_state = update.get('state')
            
            if not cell_id or not new_state:
                continue
                
            try:
                cell_uuid = UUID(cell_id) if isinstance(cell_id, str) else cell_id
                cell = notebook.get_cell(cell_uuid)
                
                if cell and hasattr(CellState, new_state.upper()):
                    cell.cell_state = CellState(new_state.lower())
                    cell.updated_at = datetime.now()
                    updated_count += 1
                    
            except (ValueError, AttributeError) as e:
                logger.warning(f"Invalid cell update: {update}, error: {e}")
                continue
        
        if updated_count > 0:
            notebook.updated_at = datetime.now()
            self._save_notebook(notebook)
            logger.info(f"Bulk updated {updated_count} cell states in notebook {notebook.title}")
        
        return True
    
    def get_cells_below_index(self, notebook_id: str, cell_index: int) -> List[Cell]:
        """
        Get all cells below a given index.
        
        Args:
            notebook_id: Notebook UUID
            cell_index: Index of the reference cell (0-based)
            
        Returns:
            List of cells below the given index
        """
        notebook = self._notebooks.get(notebook_id)
        if not notebook or cell_index < 0 or cell_index >= len(notebook.cells):
            return []
        
        return notebook.cells[cell_index + 1:]
    
    def get_cell_index(self, notebook_id: str, cell_id: str) -> int:
        """
        Get the index of a cell in the notebook.
        
        Args:
            notebook_id: Notebook UUID
            cell_id: Cell UUID (as string)
            
        Returns:
            Index of the cell (0-based), or -1 if not found
        """
        notebook = self._notebooks.get(notebook_id)
        if not notebook:
            return -1
        
        # Convert string cell_id to UUID for comparison
        try:
            cell_uuid = UUID(cell_id)
        except ValueError:
            return -1
        
        for i, cell in enumerate(notebook.cells):
            if cell.id == cell_uuid:
                return i
        
        return -1
    
    def _apply_basic_error_fixes(self, code: str, error_message: str, error_type: str) -> Optional[str]:
        """
        EMERGENCY FALLBACK ONLY - when LLM service completely fails.
        
        This should contain ONLY simple, safe transformations.
        All sophisticated error analysis belongs in ErrorAnalyzer.
        
        WARNING: This is a last resort. The primary error handling system is:
        LLMService.suggest_improvements() -> ErrorAnalyzer -> enhanced context
        """
        if not error_message or not code:
            return None
            
        logger.warning(f"ðŸš¨ FALLBACK: LLM service failed, applying basic fixes for {error_type}")
        logger.warning("ðŸš¨ This indicates ErrorAnalyzer system needs improvement for this error type")
        
        # ONLY simple, safe fixes here - DO NOT duplicate ErrorAnalyzer logic
        
        # Simple file path fix
        if error_type == "FileNotFoundError" and "data/" not in code:
            import re
            # Simple regex to add data/ prefix to common file extensions
            pattern = r"(['\"])([^'\"]*\.(csv|xlsx|json|txt))(['\"])"
            def add_prefix(match):
                quote, filepath, ext, end_quote = match.groups()
                if not filepath.startswith('data/'):
                    return f"{quote}data/{filepath}{end_quote}"
                return match.group(0)
            
            fixed_code = re.sub(pattern, add_prefix, code)
            if fixed_code != code:
                return f"# Emergency fix: Added data/ prefix to file paths\n{fixed_code}"
        
        # Simple import additions
        if error_type in ("ImportError", "ModuleNotFoundError"):
            if "seaborn" in error_message and "import seaborn" not in code:
                return f"# Emergency fix: Added missing import\nimport seaborn as sns\n{code}"
            elif "matplotlib" in error_message and "import matplotlib" not in code:
                return f"# Emergency fix: Added missing import\nimport matplotlib.pyplot as plt\n{code}"
        
        # Simple debugging addition for pandas errors
        if error_type == "KeyError" and "df[" in code:
            return f"""# Emergency fix: Added debugging info
print("Available columns:", df.columns.tolist() if 'df' in locals() and hasattr(df, 'columns') else 'No DataFrame found')

{code}"""
        
        # For pandas length mismatch, just add a helpful comment
        if "Length of values" in error_message and "does not match length of index" in error_message:
            return f"""# Emergency fix: Length mismatch detected
# Consider using safe_assign(df, 'column_name', values) for robust assignment
# This error means you're trying to assign mismatched data lengths

{code}"""
        
        logger.warning("ðŸš¨ No basic fixes available - ErrorAnalyzer system needs enhancement")
        return None

    def update_notebook(self, notebook_id: str, request: NotebookUpdateRequest) -> Optional[Notebook]:
        """
        Update notebook metadata.
        
        Args:
            notebook_id: Notebook UUID
            request: Update parameters
            
        Returns:
            Updated notebook or None if not found
        """
        notebook = self._notebooks.get(notebook_id)
        if not notebook:
            return None
        
        # Update fields
        if request.title is not None:
            notebook.title = request.title
        if request.description is not None:
            notebook.description = request.description
        if request.author is not None:
            notebook.author = request.author
        if request.tags is not None:
            notebook.tags = request.tags
        if request.llm_model is not None:
            notebook.llm_model = request.llm_model
        if request.llm_provider is not None:
            notebook.llm_provider = request.llm_provider
        
        notebook.updated_at = datetime.now()
        self._save_notebook(notebook)
        
        logger.info(f"Updated notebook: {notebook.title}")
        return notebook
    
    def delete_notebook(self, notebook_id: str) -> bool:
        """
        Delete a notebook.
        
        Args:
            notebook_id: Notebook UUID
            
        Returns:
            True if deleted, False if not found
        """
        if notebook_id not in self._notebooks:
            return False
        
        notebook = self._notebooks[notebook_id]
        
        # Remove from cache
        del self._notebooks[notebook_id]
        
        # Remove file
        notebook_file = self.notebooks_dir / f"{notebook_id}.json"
        if notebook_file.exists():
            notebook_file.unlink()
        
        logger.info(f"Deleted notebook: {notebook.title}")
        return True
    
    def create_cell(self, request: CellCreateRequest) -> Optional[Cell]:
        """
        Create a new cell in a notebook.
        
        Args:
            request: Cell creation parameters
            
        Returns:
            Created cell or None if notebook not found
        """
        notebook = self._notebooks.get(str(request.notebook_id))
        if not notebook:
            return None
        
        cell = notebook.add_cell(request.cell_type, request.content)
        self._save_notebook(notebook)
        
        logger.info(f"Created new {request.cell_type} cell in notebook {notebook.title}")
        return cell
    
    def update_cell(self, notebook_id: str, cell_id: str, request: CellUpdateRequest) -> Optional[Cell]:
        """
        Update a cell.
        
        Args:
            notebook_id: Notebook UUID
            cell_id: Cell UUID
            request: Update parameters
            
        Returns:
            Updated cell or None if not found
        """
        notebook = self._notebooks.get(notebook_id)
        if not notebook:
            logger.error(f"Notebook {notebook_id} not found")
            return None
        
        # Debug: Log available cells
        logger.info(f"Looking for cell {cell_id} in notebook {notebook_id}")
        logger.info(f"Available cells: {[str(c.id) for c in notebook.cells]}")
        
        try:
            cell_uuid = uuid.UUID(cell_id)
            cell = notebook.get_cell(cell_uuid)
            if not cell:
                logger.error(f"Cell {cell_id} not found in notebook {notebook_id}")
                return None
        except ValueError as e:
            logger.error(f"Invalid UUID format for cell_id {cell_id}: {e}")
            return None
        
        # Update fields
        if request.prompt is not None:
            cell.prompt = request.prompt
        if request.code is not None:
            cell.code = request.code
        if request.markdown is not None:
            cell.markdown = request.markdown
        if request.show_code is not None:
            cell.show_code = request.show_code
        if request.tags is not None:
            cell.tags = request.tags
        if request.metadata is not None:
            cell.metadata = request.metadata
            
        # Handle cell type changes
        if hasattr(request, 'cell_type') and request.cell_type is not None:
            old_type = cell.cell_type
            cell.cell_type = request.cell_type
            logger.info(f"Changed cell type from {old_type} to {request.cell_type}")
        
        cell.updated_at = datetime.now()
        notebook.updated_at = datetime.now()
        self._save_notebook(notebook)
        
        logger.info(f"Updated cell {cell_id} in notebook {notebook.title}")
        return cell
    
    def delete_cell(self, notebook_id: str, cell_id: str) -> bool:
        """
        Delete a cell from a notebook.
        
        Args:
            notebook_id: Notebook UUID
            cell_id: Cell UUID
            
        Returns:
            True if deleted, False if not found
        """
        notebook = self._notebooks.get(notebook_id)
        if not notebook:
            return False
        
        if notebook.remove_cell(uuid.UUID(cell_id)):
            self._save_notebook(notebook)
            logger.info(f"Deleted cell {cell_id} from notebook {notebook.title}")
            return True
        
        return False
    
    def execute_cell(self, request: CellExecuteRequest) -> Optional[tuple[Cell, ExecutionResult]]:
        """
        Execute a cell (generate code from prompt if needed and run it).
        
        Args:
            request: Execution request parameters
            
        Returns:
            Execution result or None if cell not found
        """
        print(f"ðŸ“‹ NOTEBOOK SERVICE: execute_cell called for {request.cell_id}")
        print(f"ðŸ“‹ NOTEBOOK SERVICE: force_regenerate = {request.force_regenerate}")
        logger.info(f"ðŸ“‹ NOTEBOOK SERVICE: execute_cell called for {request.cell_id}")
        logger.info(f"ðŸ“‹ NOTEBOOK SERVICE: force_regenerate = {request.force_regenerate}")
        # Find the cell
        cell = None
        notebook = None
        
        for nb in self._notebooks.values():
            found_cell = nb.get_cell(request.cell_id)
            if found_cell:
                cell = found_cell
                notebook = nb
                break
        
        if not cell or not notebook:
            logger.error(f"Cell {request.cell_id} not found")
            return None
        
        try:
            # Mark cell as executing
            cell.is_executing = True
            
            # Handle direct code execution
            if request.code:
                cell.code = request.code
                cell.updated_at = datetime.now()
            elif request.prompt:
                cell.prompt = request.prompt
                cell.updated_at = datetime.now()
            
            # Always build context for LLM (needed for both code generation and methodology)
            try:
                context = self._build_execution_context(notebook, cell)
                logger.info(f"Built context with {len(context)} items")
            except Exception as context_error:
                logger.warning(f"Context building failed: {context_error}, using empty context")
                context = {}

            # Generate code if needed
            if not cell.code or request.force_regenerate:
                if cell.cell_type == CellType.PROMPT and cell.prompt:
                    logger.info(f"Generating code for prompt: {cell.prompt[:100]}...")
                    
                    try:
                        # Update LLM service configuration
                        if notebook.llm_provider != self.llm_service.provider or notebook.llm_model != self.llm_service.model:
                            logger.info(f"Updating LLM service: {notebook.llm_provider}/{notebook.llm_model}")
                            self.llm_service = LLMService(notebook.llm_provider, notebook.llm_model)
                        
                        # Generate code
                        logger.info("Calling LLM service for code generation...")
                        generated_code, generation_time = self.llm_service.generate_code_from_prompt(cell.prompt, context)
                        cell.code = generated_code
                        cell.last_generation_time_ms = generation_time
                        cell.last_execution_timestamp = datetime.now()
                        cell.updated_at = datetime.now()
                        logger.info(f"Successfully generated {len(generated_code)} characters of code" + 
                                  (f" in {generation_time}ms" if generation_time else ""))

                        # Update notebook's last context tokens from the generation
                        try:
                            # Get the most recent cell usage which should have the input tokens
                            cell_usage = self.llm_service.token_tracker.get_cell_usage(str(cell.id))
                            if cell_usage and cell_usage.get('input_tokens', 0) > 0:
                                notebook.last_context_tokens = cell_usage['input_tokens']
                                logger.info(f"ðŸ“Š Updated notebook last_context_tokens: {cell_usage['input_tokens']}")
                        except Exception as token_err:
                            logger.warning(f"Could not update last_context_tokens: {token_err}")

                    except Exception as e:
                        logger.error(f"LLM code generation failed: {e}")
                        import traceback
                        logger.error(f"LLM error traceback: {traceback.format_exc()}")
                        # Provide fallback code for basic analysis
                        cell.code = self._generate_fallback_code(cell.prompt)
                        logger.info("Using fallback code generation")
            
            # Execute code if available
            if cell.code and cell.cell_type in (CellType.PROMPT, CellType.CODE, CellType.METHODOLOGY):
                # Set up notebook-specific context for execution
                result = self.execution_service.execute_code(cell.code, str(cell.id), str(notebook.id))
                cell.execution_count += 1
                
                # Auto-retry logic: if execution failed and we have a prompt or generated code, try to fix it with LLM
                max_retries = 5
                should_auto_retry = (
                    result.status == ExecutionStatus.ERROR and 
                    (cell.cell_type == CellType.PROMPT or 
                     (cell.cell_type in (CellType.CODE, CellType.METHODOLOGY) and cell.prompt)) and
                    cell.prompt and 
                    cell.retry_count < max_retries and  # Allow up to 3 retries
                    not request.force_regenerate
                )
                
                # Auto-retry loop with up to max_retries attempts
                while should_auto_retry:
                    # Set retry status
                    cell.is_retrying = True
                    cell.retry_count += 1
                    
                    logger.info(f"ðŸ”„ EXECUTION FAILED - Attempting auto-retry #{cell.retry_count}/{max_retries} with LLM for cell {cell.id}")
                    logger.info(f"ðŸ”„ Error: {result.error_message}")
                    print(f"ðŸ”„ AUTO-RETRY #{cell.retry_count}/{max_retries}: Attempting to fix execution error for cell {cell.id}")
                    
                    try:
                        # Build context for LLM including the error
                        context = self._build_execution_context(notebook, cell)
                        
                        # Create error context for the LLM
                        error_context = {
                            **context,
                            'previous_code': cell.code,
                            'error_message': result.error_message,
                            'error_type': result.error_type,
                            'traceback': result.traceback,
                            'stderr': result.stderr
                        }
                        
                        # Ask LLM to fix the code with enhanced error analysis from ErrorAnalyzer
                        logger.info(f"ðŸ”„ Asking LLM to fix the failed code (attempt #{cell.retry_count})...")
                        print(f"ðŸ”„ AUTO-RETRY #{cell.retry_count}: Analyzing error and generating corrected code...")

                        # Use suggest_improvements with enhanced error context
                        # This will automatically use ErrorAnalyzer to provide domain-specific guidance
                        try:
                            fixed_code = self.llm_service.suggest_improvements(
                                prompt=cell.prompt,
                                code=cell.code,
                                error_message=result.error_message,
                                error_type=result.error_type,
                                traceback=result.traceback
                            )
                        except Exception as llm_error:
                            logger.error(f"ðŸ”„ LLM service failed during retry #{cell.retry_count}: {llm_error}")
                            print(f"ðŸ”„ LLM ERROR: LLM service failed on retry #{cell.retry_count}: {llm_error}")
                            # Try basic error-specific fixes when LLM fails
                            fixed_code = self._apply_basic_error_fixes(cell.code, result.error_message, result.error_type)
                        
                        if fixed_code and fixed_code != cell.code:
                            logger.info(f"ðŸ”„ LLM provided fixed code ({len(fixed_code)} chars)")
                            print(f"ðŸ”„ UPDATED: LLM provided corrected code for retry #{cell.retry_count}")
                            cell.code = fixed_code
                            cell.updated_at = datetime.now()
                            
                            # Try executing the fixed code
                            logger.info("ðŸ”„ Executing fixed code...")
                            print(f"ðŸ”„ EXECUTING: Testing corrected code...")
                            retry_result = self.execution_service.execute_code(cell.code, str(cell.id), str(notebook.id))
                            
                            if retry_result.status == ExecutionStatus.SUCCESS:
                                logger.info(f"ðŸ”„ âœ… Auto-retry #{cell.retry_count} successful! Fixed code executed successfully")
                                print(f"ðŸ”„ SUCCESS: Auto-retry #{cell.retry_count} fixed the error for cell {cell.id}")
                                result = retry_result
                                cell.execution_count += 1
                                cell.is_retrying = False  # Clear retry status on success
                                break  # Exit retry loop on success
                            else:
                                logger.warning(f"ðŸ”„ âŒ Auto-retry #{cell.retry_count} failed: {retry_result.error_message}")
                                print(f"ðŸ”„ RETRY #{cell.retry_count} FAILED: {retry_result.error_message}")
                                result = retry_result  # Update result for next iteration
                        else:
                            logger.warning(f"ðŸ”„ LLM did not provide different code for retry #{cell.retry_count}")
                            print(f"ðŸ”„ NO CHANGE: LLM provided same code on retry #{cell.retry_count}")
                            # When LLM provides same code, we should still continue retrying
                            # The error persists, so we keep the current result
                        
                        # Check if we should continue retrying
                        if cell.retry_count >= max_retries:
                            logger.warning(f"ðŸ”„ All {max_retries} retries exhausted for cell {cell.id}")
                            print(f"ðŸ”„ EXHAUSTED: All {max_retries} auto-retry attempts failed for cell {cell.id}")
                            cell.is_retrying = False  # Clear retry status
                            break
                        
                        # Update should_auto_retry for next iteration
                        should_auto_retry = (
                            result.status == ExecutionStatus.ERROR and 
                            cell.retry_count < max_retries
                        )
                            
                    except Exception as retry_error:
                        logger.error(f"ðŸ”„ Auto-retry #{cell.retry_count} mechanism failed: {retry_error}")
                        print(f"ðŸ”„ ERROR: Auto-retry #{cell.retry_count} mechanism failed: {retry_error}")
                        
                        if cell.retry_count >= max_retries:
                            cell.is_retrying = False  # Clear retry status on exception
                            break
                        
                        # Continue to next retry attempt
                        should_auto_retry = (cell.retry_count < max_retries)
            else:
                # For markdown cells or empty cells
                result = ExecutionResult(status=ExecutionStatus.SUCCESS)
            
            # Update cell with result
            cell.last_result = result
            cell.is_executing = False
            notebook.updated_at = datetime.now()
            
            # Generate scientific explanation for successful prompt cells
            print(f"ðŸ”¬ ALWAYS CHECKING scientific explanation conditions:")
            print(f"   - Result status: {result.status} (SUCCESS={ExecutionStatus.SUCCESS})")
            print(f"   - Cell type: {cell.cell_type} (PROMPT={CellType.PROMPT}, CODE={CellType.CODE})")
            print(f"   - Has prompt: {bool(cell.prompt)} ('{cell.prompt[:50] if cell.prompt else 'None'}...')")
            print(f"   - Has code: {bool(cell.code)} ('{cell.code[:50] if cell.code else 'None'}...')")
            logger.info(f"ðŸ”¬ ALWAYS CHECKING scientific explanation conditions:")
            logger.info(f"   - Result status: {result.status} (SUCCESS={ExecutionStatus.SUCCESS})")
            logger.info(f"   - Cell type: {cell.cell_type} (PROMPT={CellType.PROMPT}, CODE={CellType.CODE})")
            logger.info(f"   - Has prompt: {bool(cell.prompt)} ('{cell.prompt[:50] if cell.prompt else 'None'}...')")
            logger.info(f"   - Has code: {bool(cell.code)} ('{cell.code[:50] if cell.code else 'None'}...')")
            
            # Generate scientific explanation for any successful execution with code and prompt
            # This includes both PROMPT cells and CODE cells that have been manually edited
            if (result.status == ExecutionStatus.SUCCESS and 
                cell.prompt and cell.code and
                cell.cell_type in (CellType.PROMPT, CellType.CODE)):
                
                print("ðŸ”¬ GENERATING SCIENTIFIC EXPLANATION SYNCHRONOUSLY...")
                logger.info("ðŸ”¬ GENERATING SCIENTIFIC EXPLANATION SYNCHRONOUSLY...")
                
                try:
                    # Prepare execution result data for LLM
                    execution_data = {
                        'status': 'success',
                        'stdout': result.stdout,
                        'plots': result.plots,
                        'tables': result.tables,
                        'interactive_plots': result.interactive_plots
                    }
                    
                    print("ðŸ”¬ About to call LLM service for methodology...")
                    explanation, explanation_gen_time = self.llm_service.generate_scientific_explanation(
                        cell.prompt, 
                        cell.code, 
                        execution_data,
                        context  # Pass context for seed consistency
                    )
                    print(f"ðŸ”¬ LLM returned explanation: {len(explanation)} chars" + 
                          (f" in {explanation_gen_time}ms" if explanation_gen_time else ""))
                    print(f"ðŸ”¬ Explanation content: {explanation[:200]}...")
                    
                    # Update cell with explanation
                    cell.scientific_explanation = explanation
                    # Note: We don't update last_generation_time_ms here as it's for code generation
                    print(f"ðŸ”¬ Cell updated with explanation: {len(cell.scientific_explanation)} chars")
                    
                    # Update notebook's last context tokens from methodology generation
                    try:
                        # Get the most recent cell usage which should have the input tokens from methodology generation
                        cell_usage = self.llm_service.token_tracker.get_cell_usage(str(cell.id))
                        if cell_usage and cell_usage.get('input_tokens', 0) > 0:
                            notebook.last_context_tokens = cell_usage['input_tokens']
                            logger.info(f"ðŸ“Š Updated notebook last_context_tokens from methodology: {cell_usage['input_tokens']}")
                    except Exception as token_err:
                        logger.warning(f"Could not update last_context_tokens from methodology: {token_err}")
                    
                except Exception as e:
                    print(f"ðŸ”¬ ERROR generating scientific explanation: {e}")
                    import traceback
                    print(f"ðŸ”¬ Traceback: {traceback.format_exc()}")
                    logger.error(f"Error generating scientific explanation: {e}")
                    cell.scientific_explanation = ""
            else:
                logger.info("ðŸ”¬ Skipping scientific explanation generation (conditions not met)")
            
            # Update cell state management
            if result.status == ExecutionStatus.SUCCESS:
                # Mark this cell as fresh
                cell.cell_state = CellState.FRESH

                # Mark downstream cells as stale
                try:
                    cell_index = self.get_cell_index(str(notebook.id), cell.id)
                    if cell_index >= 0:
                        self.mark_cells_as_stale(str(notebook.id), cell_index)
                        logger.info(f"Marked cells below index {cell_index} as stale")
                except Exception as e:
                    logger.warning(f"Failed to mark downstream cells as stale: {e}")

            # Extract semantic information from cell (non-blocking)
            try:
                logger.info(f"ðŸ” Extracting semantic information from cell {cell.id}...")
                cell_semantics = self.semantic_service.extract_cell_semantics(cell, notebook)
                cell.metadata['semantics'] = cell_semantics.to_jsonld()
                logger.info(f"âœ… Extracted {len(cell_semantics.triples)} triples, " +
                           f"{len(cell_semantics.libraries_used)} libraries, " +
                           f"{len(cell_semantics.methods_used)} methods")
            except Exception as e:
                logger.warning(f"âš ï¸ Semantic extraction failed (non-critical): {e}")
                # Don't let semantic extraction errors break execution
                pass

            # Save notebook
            self._save_notebook(notebook)
            
            logger.info(f"Executed cell {cell.id} with status {result.status}")
            return cell, result
            
        except Exception as e:
            # Handle execution errors
            error_result = ExecutionResult(
                status=ExecutionStatus.ERROR,
                error_type=type(e).__name__,
                error_message=str(e),
                traceback=str(e)
            )
            
            cell.last_result = error_result
            cell.is_executing = False
            self._save_notebook(notebook)
            
            logger.error(f"Failed to execute cell {cell.id}: {e}")
            return cell, error_result

    def _save_notebook(self, notebook: Notebook):
        """
        Save a notebook to disk using atomic write pattern.
        
        Args:
            notebook: Notebook to save
        """
        try:
            notebook_file = self.notebooks_dir / f"{notebook.id}.json"
            temp_file = self.notebooks_dir / f"{notebook.id}.json.tmp"
            
            # Write to temporary file first
            with open(temp_file, 'w', encoding='utf-8') as f:
                json.dump(
                    notebook.dict(),
                    f,
                    indent=2,
                    ensure_ascii=False,
                    default=str  # Handle UUID and datetime serialization
                )
            
            # Atomic rename - this is the critical part that prevents corruption
            temp_file.rename(notebook_file)
            
        except Exception as e:
            logger.error(f"Failed to save notebook {notebook.title}: {e}")
            # Clean up temporary file if it exists
            temp_file = self.notebooks_dir / f"{notebook.id}.json.tmp"
            if temp_file.exists():
                temp_file.unlink()
    
    def export_notebook(self, notebook_id: str, format: str = "json") -> Optional[str]:
        """
        Export a notebook in various formats.

        Args:
            notebook_id: Notebook UUID
            format: Export format (json, html, markdown, jsonld, semantic)

        Returns:
            Exported content or None if notebook not found
        """
        notebook = self._notebooks.get(notebook_id)
        if not notebook:
            return None

        if format == "json":
            return json.dumps(self._create_clean_export_structure(notebook), indent=2, default=str)
        elif format == "jsonld" or format == "semantic":
            return self._export_to_jsonld(notebook)
        elif format == "analysis":
            return self._export_analysis_graph(notebook)
        elif format == "profile":
            return self._export_profile_graph(notebook)
        elif format == "markdown":
            return self._export_to_markdown(notebook)
        elif format == "html":
            return self._export_to_html(notebook)
        else:
            raise ValueError(f"Unsupported export format: {format}")
    
    def _create_clean_export_structure(self, notebook: Notebook) -> Dict[str, Any]:
        """
        Create a clean, optimized export structure for JSON export.
        
        This structure focuses on the essential content and metadata,
        removing internal application state and execution details.
        
        Args:
            notebook: Notebook to export
            
        Returns:
            Clean dictionary structure for export
        """
        # Core notebook metadata
        export_data = {
            "digital_article": {
                "version": "0.0.3",
                "export_timestamp": datetime.now().isoformat()
            },
            "metadata": {
                "id": str(notebook.id),
                "title": notebook.title,
                "description": notebook.description,
                "author": notebook.author,
                "created_at": notebook.created_at.isoformat(),
                "updated_at": notebook.updated_at.isoformat(),
                "version": notebook.version,
                "tags": notebook.tags,
                "abstract": notebook.abstract,
                "abstract_generated_at": notebook.abstract_generated_at.isoformat() if notebook.abstract_generated_at else None
            },
            "configuration": {
                "llm_provider": notebook.llm_provider,
                "llm_model": notebook.llm_model
            },
            "cells": []
        }
        
        # Process cells with clean structure
        for cell in notebook.cells:
            cell_data = {
                "id": str(cell.id),
                "type": cell.cell_type.value,
                "created_at": cell.created_at.isoformat(),
                "updated_at": cell.updated_at.isoformat(),
                "content": {}
            }
            
            # Core content based on cell type
            if cell.cell_type == CellType.PROMPT:
                cell_data["content"] = {
                    "prompt": cell.prompt,
                    "code": cell.code,
                    "methodology": cell.scientific_explanation
                }
            elif cell.cell_type == CellType.CODE:
                cell_data["content"] = {
                    "code": cell.code,
                    "methodology": cell.scientific_explanation if cell.scientific_explanation else None
                }
            elif cell.cell_type == CellType.MARKDOWN:
                cell_data["content"] = {
                    "markdown": cell.markdown
                }
            elif cell.cell_type == CellType.METHODOLOGY:
                cell_data["content"] = {
                    "prompt": cell.prompt,
                    "code": cell.code,
                    "methodology": cell.scientific_explanation
                }
            
            # Execution summary (without heavy data)
            if cell.last_result and cell.last_result.status == ExecutionStatus.SUCCESS:
                cell_data["execution"] = {
                    "status": "success",
                    "execution_count": cell.execution_count,
                    "last_executed": cell.last_result.timestamp.isoformat(),
                    "execution_time": cell.last_result.execution_time,
                    "has_output": bool(cell.last_result.stdout),
                    "has_plots": len(cell.last_result.plots) > 0,
                    "has_tables": len(cell.last_result.tables) > 0,
                    "has_interactive_plots": len(cell.last_result.interactive_plots) > 0
                }
            elif cell.last_result and cell.last_result.status == ExecutionStatus.ERROR:
                cell_data["execution"] = {
                    "status": "error",
                    "execution_count": cell.execution_count,
                    "last_executed": cell.last_result.timestamp.isoformat(),
                    "error_type": cell.last_result.error_type,
                    "error_message": cell.last_result.error_message
                }
            else:
                cell_data["execution"] = {
                    "status": "not_executed",
                    "execution_count": cell.execution_count
                }
            
            # Optional metadata
            if cell.tags:
                cell_data["tags"] = cell.tags
            if cell.metadata:
                cell_data["metadata"] = cell.metadata
                
            export_data["cells"].append(cell_data)
        
        return export_data
    
    def _export_to_markdown(self, notebook: Notebook) -> str:
        """Export notebook to Markdown format."""
        md_lines = [
            f"# {notebook.title}",
            "",
            notebook.description,
            "",
            f"**Author:** {notebook.author}",
            f"**Created:** {notebook.created_at.isoformat()}",
            f"**Updated:** {notebook.updated_at.isoformat()}",
            ""
        ]
        
        for i, cell in enumerate(notebook.cells, 1):
            md_lines.append(f"## Cell {i}")
            
            if cell.cell_type == CellType.PROMPT:
                md_lines.extend([
                    "**Prompt:**",
                    cell.prompt,
                    "",
                    "**Generated Code:**",
                    f"```python",
                    cell.code,
                    "```",
                    ""
                ])
            elif cell.cell_type == CellType.CODE:
                md_lines.extend([
                    "**Code:**",
                    f"```python",
                    cell.code,
                    "```",
                    ""
                ])
            elif cell.cell_type == CellType.MARKDOWN:
                md_lines.extend([cell.markdown, ""])
            
            # Add execution results if available
            if cell.last_result and cell.last_result.status == ExecutionStatus.SUCCESS:
                if cell.last_result.stdout:
                    md_lines.extend([
                        "**Output:**",
                        "```",
                        cell.last_result.stdout,
                        "```",
                        ""
                    ])
        
        return "\n".join(md_lines)

    def _export_to_jsonld(self, notebook: Notebook) -> str:
        """
        Export notebook to JSON-LD semantic graph format.

        This creates a JSON-LD representation of the notebook with:
        - Standard ontology context (Dublin Core, Schema.org, SKOS, CiTO, PROV)
        - Semantic entities (notebooks, cells, datasets, methods, etc.)
        - Relationships as RDF triples
        - Knowledge graph for cross-notebook interoperability

        Returns:
            JSON string with JSON-LD representation
        """
        try:
            # Extract complete notebook semantics
            notebook_semantics = self.semantic_service.extract_notebook_semantics(notebook)

            # Get the JSON-LD graph representation
            jsonld_data = notebook_semantics.to_jsonld_graph()

            # Enhance with notebook content for hybrid export
            # This combines semantic data with readable content
            enhanced_export = {
                "@context": jsonld_data["@context"],
                "metadata": {
                    "digital_article": {
                        "version": "0.0.3",
                        "export_timestamp": datetime.now().isoformat(),
                        "export_format": "jsonld"
                    },
                    "notebook": {
                        "id": str(notebook.id),
                        "title": notebook.title,
                        "description": notebook.description,
                        "author": notebook.author,
                        "created_at": notebook.created_at.isoformat(),
                        "updated_at": notebook.updated_at.isoformat()
                    },
                    "semantic_summary": {
                        "total_cells": len(notebook.cells),
                        "total_entities": jsonld_data["metadata"]["total_entities"],
                        "total_triples": jsonld_data["metadata"]["total_triples"],
                        "datasets_used": notebook_semantics.get_all_datasets(),
                        "methods_used": notebook_semantics.get_all_methods(),
                        "libraries_used": notebook_semantics.get_all_libraries(),
                        "concepts_mentioned": notebook_semantics.get_all_concepts()
                    }
                },
                "@graph": jsonld_data["@graph"],
                "triples": jsonld_data["triples"],
                "cells": []
            }

            # Add cell-level semantic annotations
            for cell, cell_semantics in zip(notebook.cells, notebook_semantics.cell_semantics):
                cell_export = {
                    "id": str(cell.id),
                    "type": cell.cell_type.value,
                    "semantic_id": cell_semantics.cell_id,
                    "content": {
                        "prompt": cell.prompt if cell.prompt else None,
                        "code": cell.code if cell.code else None,
                        "methodology": cell.scientific_explanation if cell.scientific_explanation else None
                    },
                    "semantics": {
                        "intent_tags": cell_semantics.intent_tags,
                        "libraries_used": cell_semantics.libraries_used,
                        "methods_used": cell_semantics.methods_used,
                        "datasets_used": cell_semantics.datasets_used,
                        "variables_defined": cell_semantics.variables_defined,
                        "concepts_mentioned": cell_semantics.concepts_mentioned,
                        "statistical_findings": cell_semantics.statistical_findings,
                        "entity_count": len(cell_semantics.entities),
                        "triple_count": len(cell_semantics.triples)
                    }
                }
                enhanced_export["cells"].append(cell_export)

            return json.dumps(enhanced_export, indent=2, default=str, ensure_ascii=False)

        except Exception as e:
            logger.error(f"Error exporting notebook to JSON-LD: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            # Fallback to basic JSON export with error note
            basic_export = self._create_clean_export_structure(notebook)
            basic_export["export_error"] = {
                "message": "Semantic extraction failed, falling back to standard JSON export",
                "error": str(e)
            }
            return json.dumps(basic_export, indent=2, default=str)

    def _export_analysis_graph(self, notebook: Notebook) -> str:
        """
        Export analysis flow knowledge graph.

        Focuses on workflow and process:
        - Cell execution sequence
        - Variable definitions and reuse
        - Data transformations
        - Method application order
        """
        try:
            analysis_graph = self.analysis_graph_service.extract_analysis_graph(notebook)
            return json.dumps(analysis_graph, indent=2, default=str, ensure_ascii=False)
        except Exception as e:
            logger.error(f"Error exporting analysis graph: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            # Fallback
            return json.dumps({
                "@context": {},
                "@graph": [],
                "error": f"Analysis graph extraction failed: {str(e)}"
            }, indent=2)

    def _export_profile_graph(self, notebook: Notebook) -> str:
        """
        Export profile knowledge graph.

        Focuses on data and user:
        - Data types and standards
        - Analysis categories
        - User skills (technical and domain)
        - Research interests
        """
        try:
            profile_graph = self.profile_graph_service.extract_profile_graph(notebook)
            return json.dumps(profile_graph, indent=2, default=str, ensure_ascii=False)
        except Exception as e:
            logger.error(f"Error exporting profile graph: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            # Fallback
            return json.dumps({
                "@context": {},
                "@graph": [],
                "error": f"Profile graph extraction failed: {str(e)}"
            }, indent=2)

    def _export_to_html(self, notebook: Notebook) -> str:
        """Export notebook to HTML format."""
        # This would be implemented with a proper HTML template
        # For now, return basic HTML structure
        html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>{notebook.title}</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 40px; }}
                .cell {{ margin: 20px 0; padding: 15px; border: 1px solid #ddd; }}
                .prompt {{ background-color: #f8f9fa; }}
                .code {{ background-color: #f1f3f4; font-family: monospace; }}
                .output {{ background-color: #e8f5e8; }}
            </style>
        </head>
        <body>
            <h1>{notebook.title}</h1>
            <p>{notebook.description}</p>
            <p><strong>Author:</strong> {notebook.author}</p>
        """
        
        for i, cell in enumerate(notebook.cells, 1):
            if cell.cell_type == CellType.PROMPT:
                html += f"""
                <div class="cell">
                    <h3>Cell {i} - Prompt</h3>
                    <div class="prompt">{cell.prompt}</div>
                    <div class="code"><pre>{cell.code}</pre></div>
                </div>
                """
        
        html += "</body></html>"
        return html
    
    def export_notebook_pdf(self, notebook_id: str, include_code: bool = False) -> Optional[bytes]:
        """
        Export a notebook to PDF format as a complete scientific article.
        
        This method:
        1. Regenerates the abstract to ensure it's current
        2. Uses LLM to generate a complete article plan and content
        3. Creates a human-readable scientific article with proper structure
        4. Includes empirical evidence and acknowledgments
        
        Args:
            notebook_id: Notebook UUID
            include_code: Whether to include generated code in the PDF
            
        Returns:
            PDF content as bytes or None if notebook not found
        """
        notebook = self._notebooks.get(notebook_id)
        if not notebook:
            return None
        
        try:
            logger.info(f"Exporting notebook {notebook_id} to LLM-generated scientific article PDF (include_code={include_code})")
            
            # Step 1: Regenerate abstract to ensure it's current
            logger.info("ðŸŽ¯ Step 1: Regenerating abstract for PDF export...")
            try:
                self.generate_abstract(notebook_id)
                # Reload notebook to get updated abstract
                notebook = self._notebooks.get(notebook_id)
            except Exception as e:
                logger.warning(f"Failed to regenerate abstract for PDF: {e}")
                # Continue with existing abstract or empty if none
            
            # Step 2: Generate complete scientific article using LLM
            logger.info("ðŸŽ¯ Step 2: Generating complete scientific article...")
            scientific_article = self.generate_scientific_article(notebook_id)
            
            # Step 3: Generate PDF from the LLM-generated article
            logger.info("ðŸŽ¯ Step 3: Creating PDF from scientific article...")
            pdf_bytes = self.pdf_service.generate_scientific_article_pdf(scientific_article, notebook, include_code)
            
            logger.info(f"ðŸŽ¯ LLM-driven scientific PDF export successful: {len(pdf_bytes)} bytes")
            return pdf_bytes
        except Exception as e:
            logger.error(f"Failed to export notebook {notebook_id} to PDF: {e}")
            raise
    
    def set_notebook_custom_seed(self, notebook_id: str, seed: int) -> bool:
        """
        Set a custom seed for notebook reproducibility.
        
        This seed will be used for both LLM generation and execution environment
        to ensure complete reproducibility.
        
        Args:
            notebook_id: Notebook identifier
            seed: Custom seed value (0-2147483647)
            
        Returns:
            True if successful, False if notebook not found
        """
        notebook = self._notebooks.get(notebook_id)
        if not notebook:
            return False
        
        # Store custom seed in notebook metadata
        if not hasattr(notebook, 'custom_seed'):
            notebook.custom_seed = None
        notebook.custom_seed = seed
        
        # Update both LLM and execution services to use this seed
        try:
            # Update LLM service seed (will be used in next generation)
            if not hasattr(self.llm_service, '_custom_seeds'):
                self.llm_service._custom_seeds = {}
            self.llm_service._custom_seeds[notebook_id] = seed
            
            # Update execution service seed (will be used in next execution)
            self.execution_service.notebook_execution_seed = None  # Reset to force re-initialization
            if not hasattr(self.execution_service, '_custom_seeds'):
                self.execution_service._custom_seeds = {}
            self.execution_service._custom_seeds[notebook_id] = seed
            
            logger.info(f"ðŸŽ² Set custom seed {seed} for notebook {notebook_id}")
            
            # Save notebook with new seed
            self._save_notebook(notebook)
            return True
            
        except Exception as e:
            logger.error(f"Failed to set custom seed: {e}")
            return False

    def generate_abstract(self, notebook_id: str) -> str:
        """
        Generate a scientific abstract for the entire digital article.
        
        Args:
            notebook_id: ID of the notebook to generate abstract for
            
        Returns:
            Generated abstract as a string
            
        Raises:
            ValueError: If notebook not found
            Exception: If abstract generation fails
        """
        notebook = self._notebooks.get(notebook_id)
        if not notebook:
            raise ValueError(f"Notebook {notebook_id} not found")
        
        try:
            # Convert notebook to dictionary format for LLM service
            notebook_data = {
                'id': str(notebook.id),
                'title': notebook.title,
                'description': notebook.description,
                'author': notebook.author,
                'cells': []
            }
            
            # Convert cells to dictionary format
            for cell in notebook.cells:
                cell_data = {
                    'prompt': cell.prompt,
                    'code': cell.code,
                    'scientific_explanation': cell.scientific_explanation,
                    'last_result': None
                }
                
                # Include execution results if available
                if cell.last_result:
                    cell_data['last_result'] = {
                        'output': cell.last_result.stdout,  # Use stdout instead of output
                        'status': cell.last_result.status.value if cell.last_result.status else None,
                        'execution_time': cell.last_result.execution_time
                    }
                
                notebook_data['cells'].append(cell_data)
            
            # Generate abstract using LLM service
            abstract = self.llm_service.generate_abstract(notebook_data)
            
            # Save abstract to notebook
            notebook.abstract = abstract
            notebook.abstract_generated_at = datetime.now()
            self._save_notebook(notebook)
            
            logger.info(f"ðŸŽ¯ Generated and saved abstract for notebook {notebook_id}: {len(abstract)} characters")
            return abstract
            
        except Exception as e:
            logger.error(f"Failed to generate abstract for notebook {notebook_id}: {e}")
            raise

    def generate_scientific_article(self, notebook_id: str) -> Dict[str, Any]:
        """
        Generate a complete scientific article with LLM-driven content.
        
        Args:
            notebook_id: ID of the notebook to generate article for
            
        Returns:
            Dictionary with article structure and content
            
        Raises:
            ValueError: If notebook not found
            Exception: If article generation fails
        """
        notebook = self._notebooks.get(notebook_id)
        if not notebook:
            raise ValueError(f"Notebook {notebook_id} not found")
        
        try:
            logger.info(f"ðŸŽ¯ Generating complete scientific article for notebook {notebook_id}")
            
            # Convert notebook to dictionary format for LLM service
            notebook_data = {
                'id': str(notebook.id),
                'title': notebook.title,
                'description': notebook.description,
                'author': notebook.author,
                'abstract': notebook.abstract,
                'cells': []
            }
            
            # Convert cells to dictionary format
            for cell in notebook.cells:
                cell_data = {
                    'prompt': cell.prompt,
                    'code': cell.code,
                    'scientific_explanation': cell.scientific_explanation,
                    'last_result': None
                }
                
                # Include execution results if available
                if cell.last_result:
                    cell_data['last_result'] = {
                        'output': cell.last_result.stdout,
                        'status': cell.last_result.status.value if cell.last_result.status else None,
                        'execution_time': cell.last_result.execution_time,
                        'plots': cell.last_result.plots if cell.last_result.plots else []
                    }
                
                notebook_data['cells'].append(cell_data)
            
            # Step 1: Generate article plan
            logger.info("ðŸŽ¯ Step 1: Generating article plan...")
            article_plan = self.llm_service.generate_article_plan(notebook_data)
            
            # Step 2: Generate each section based on the plan
            logger.info("ðŸŽ¯ Step 2: Generating article sections...")
            sections = {}
            section_names = ['introduction', 'methodology', 'results', 'discussion', 'conclusions']
            
            for section_name in section_names:
                if section_name in article_plan.get('sections', {}):
                    logger.info(f"ðŸŽ¯ Generating {section_name} section...")
                    section_plan = article_plan['sections'][section_name]
                    section_content = self.llm_service.generate_article_section(
                        section_name, section_plan, notebook_data, article_plan
                    )
                    sections[section_name] = section_content
                else:
                    logger.warning(f"ðŸŽ¯ No plan found for {section_name} section, skipping...")
            
            # Step 3: Compile complete article
            complete_article = {
                'title': article_plan.get('title', notebook.title),
                'abstract': notebook.abstract,
                'sections': sections,
                'metadata': {
                    'author': notebook.author,
                    'generated_at': datetime.now().isoformat(),
                    'notebook_id': notebook_id,
                    'digital_article_version': '0.0.3'
                },
                'plan': article_plan
            }
            
            logger.info(f"ðŸŽ¯ Generated complete scientific article for notebook {notebook_id}")
            logger.info(f"ðŸŽ¯ Article sections: {list(sections.keys())}")
            logger.info(f"ðŸŽ¯ Total content length: {sum(len(content) for content in sections.values())} characters")
            
            return complete_article
            
        except Exception as e:
            logger.error(f"Failed to generate scientific article for notebook {notebook_id}: {e}")
            raise
